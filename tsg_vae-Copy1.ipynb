{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "substantial-desert",
   "metadata": {},
   "source": [
    "# import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vocational-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import tensorflow as tf, re, math\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "import gc\n",
    "import uproot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-spain",
   "metadata": {},
   "source": [
    "### Checking for TPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "favorite-recall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not connected to a TPU runtime. Using CPU/GPU strategy\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "/usr/bin/sh: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "    print(\"Running on TPU \", tpu.cluster_spec().as_dict()[\"worker\"])\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except ValueError:\n",
    "    print(\"Not connected to a TPU runtime. Using CPU/GPU strategy\")\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    \n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-legend",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "liked-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is literally every feature that gets popped out of the ntuplizer\n",
    "def get_features():\n",
    "    return ['FatJet_pt', 'FatJet_eta', 'FatJet_phi', 'FatJet_DDX_jetNSecondaryVertices', 'FatJet_DDX_jetNTracks', 'FatJet_DDX_z_ratio', 'FatJet_Proba', 'FatJet_area', 'FatJet_jetId', 'FatJet_lsf3', 'FatJet_mass', 'FatJet_msoftdrop', 'FatJet_rawFactor', 'FatJet_n2b1', 'FatJet_n3b1', 'FatJet_tau1', 'FatJet_DDX_tau1_flightDistance2dSig', 'FatJet_DDX_tau1_trackEtaRel_0', 'FatJet_DDX_tau1_trackEtaRel_1', 'FatJet_DDX_tau1_trackEtaRel_2', 'FatJet_DDX_tau1_trackSip3dSig_0', 'FatJet_DDX_tau1_trackSip3dSig_1', 'FatJet_DDX_tau1_vertexDeltaR', 'FatJet_DDX_tau1_vertexEnergyRatio', 'FatJet_DDX_tau1_vertexMass', 'FatJet_tau2', 'FatJet_DDX_tau2_flightDistance2dSig', 'FatJet_DDX_tau2_trackEtaRel_0', 'FatJet_DDX_tau2_trackEtaRel_1', 'FatJet_DDX_tau2_trackEtaRel_3', 'FatJet_DDX_tau2_trackSip3dSig_0', 'FatJet_DDX_tau2_trackSip3dSig_1', 'FatJet_DDX_tau2_vertexEnergyRatio', 'FatJet_DDX_tau2_vertexMass', 'FatJet_tau3', 'FatJet_tau4', 'FatJet_DDX_trackSip2dSigAboveBottom_0', 'FatJet_DDX_trackSip2dSigAboveBottom_1', 'FatJet_DDX_trackSip2dSigAboveCharm', 'FatJet_DDX_trackSip3dSig_0', 'FatJet_DDX_trackSip3dSig_1', 'FatJet_DDX_trackSip3dSig_2', 'FatJet_DDX_trackSip3dSig_3', 'FatJet_subjet1_pt', 'FatJet_subjet1_eta', 'FatJet_subjet1_phi', 'FatJet_subjet1_Proba', 'FatJet_subjet1_mass', 'FatJet_subjet1_tau1', 'FatJet_subjet1_tau2', 'FatJet_subjet1_tau3', 'FatJet_subjet1_tau4', 'FatJet_subjet1_n2b1', 'FatJet_subjet1_n3b1', 'FatJet_subjet2_pt', 'FatJet_subjet2_eta', 'FatJet_subjet2_phi', 'FatJet_subjet2_Proba', 'FatJet_subjet2_mass', 'FatJet_subjet2_tau1', 'FatJet_subjet2_tau2', 'FatJet_subjet2_tau3', 'FatJet_subjet2_tau4', 'FatJet_subjet2_n2b1', 'FatJet_subjet2_n3b1', 'FatJet_hadronFlavour', 'FatJet_sv_costhetasvpv', 'FatJet_sv_d3dsig', 'FatJet_sv_deltaR', 'FatJet_sv_dxysig', 'FatJet_sv_enration', 'FatJet_sv_mass', 'FatJet_sv_normchi2', 'FatJet_sv_ntracks', 'FatJet_sv_phirel', 'FatJet_sv_pt', 'FatJet_sv_ptrel', 'FatJet_nFatJetPFCands', 'FatJet_pfcand_max_deltar', 'FatJet_pfcand_mean_deltar', 'FatJet_gen_pt', 'FatJet_gen_eta', 'FatJet_gen_phi', 'FatJet_gen_hadronFlavour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "informational-inventory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376907, 59)\n",
      "next data has shape (353590, 59)\n",
      "next data has shape (340485, 59)\n",
      "next data has shape (74979, 59)\n",
      "next data has shape (361458, 59)\n",
      "next data has shape (399367, 59)\n",
      "X has shape (1906786, 59)\n"
     ]
    }
   ],
   "source": [
    "def get_df(root_file_name, filter_name):\n",
    "    events = uproot.open(root_file_name, filter_name=filter_name)[\"tree\"]\n",
    "    df = events.arrays(library=\"pd\")\n",
    "    return df\n",
    "\n",
    "features = []\n",
    "# variables: general\n",
    "features += ['FatJet_pt', 'FatJet_eta', 'FatJet_phi', 'FatJet_DDX_jetNSecondaryVertices', \\\n",
    "             'FatJet_DDX_jetNTracks', 'FatJet_DDX_z_ratio', 'FatJet_Proba', 'FatJet_area', \\\n",
    "             'FatJet_jetId', 'FatJet_lsf3', 'FatJet_rawFactor', 'FatJet_n2b1', 'FatJet_n3b1', \\\n",
    "            ]\n",
    "\n",
    "# variables: tau1\n",
    "features += ['FatJet_tau1', 'FatJet_DDX_tau1_flightDistance2dSig', 'FatJet_DDX_tau1_trackEtaRel_0', \\\n",
    "             'FatJet_DDX_tau1_trackEtaRel_1', 'FatJet_DDX_tau1_trackEtaRel_2', 'FatJet_DDX_tau1_trackSip3dSig_0', \\\n",
    "             'FatJet_DDX_tau1_trackSip3dSig_1', 'FatJet_DDX_tau1_vertexDeltaR', 'FatJet_DDX_tau1_vertexEnergyRatio', \\\n",
    "            ]\n",
    "\n",
    "# variables: tau2\n",
    "features += ['FatJet_tau2', 'FatJet_DDX_tau2_flightDistance2dSig', 'FatJet_DDX_tau2_trackEtaRel_0', \\\n",
    "             'FatJet_DDX_tau2_trackEtaRel_1', 'FatJet_DDX_tau2_trackEtaRel_3', 'FatJet_DDX_tau2_trackSip3dSig_0', \\\n",
    "             'FatJet_DDX_tau2_trackSip3dSig_1', 'FatJet_DDX_tau2_vertexEnergyRatio', \\\n",
    "            ]\n",
    "\n",
    "# variables: tau3 and tau4\n",
    "features += ['FatJet_tau3', 'FatJet_tau4',]\n",
    "\n",
    "# variables: track\n",
    "features += ['FatJet_DDX_trackSip2dSigAboveBottom_0', 'FatJet_DDX_trackSip2dSigAboveBottom_1', \\\n",
    "             'FatJet_DDX_trackSip2dSigAboveCharm', 'FatJet_DDX_trackSip3dSig_0', \\\n",
    "             'FatJet_DDX_trackSip3dSig_1', 'FatJet_DDX_trackSip3dSig_2', 'FatJet_DDX_trackSip3dSig_3', \\\n",
    "            ]\n",
    "\n",
    "# variables: subjet 1\n",
    "features += ['FatJet_subjet1_pt', 'FatJet_subjet1_eta', 'FatJet_subjet1_phi', \\\n",
    "             'FatJet_subjet1_Proba', 'FatJet_subjet1_tau1', 'FatJet_subjet1_tau2', \\\n",
    "             'FatJet_subjet1_tau3', 'FatJet_subjet1_tau4', 'FatJet_subjet1_n2b1', 'FatJet_subjet1_n3b1', \\\n",
    "            ]\n",
    "\n",
    "# variables: subjet 2\n",
    "features += ['FatJet_subjet2_pt', 'FatJet_subjet2_eta', 'FatJet_subjet2_phi', \\\n",
    "             'FatJet_subjet2_Proba', 'FatJet_subjet2_tau1', 'FatJet_subjet2_tau2', \\\n",
    "             'FatJet_subjet2_tau3', 'FatJet_subjet2_tau4', 'FatJet_subjet2_n2b1', 'FatJet_subjet2_n3b1', \\\n",
    "            ]\n",
    "\n",
    "# # variables: fatjet sv\n",
    "# features += ['FatJet_sv_costhetasvpv', 'FatJet_sv_d3dsig', 'FatJet_sv_deltaR', 'FatJet_sv_dxysig', \\\n",
    "#              'FatJet_sv_enration', 'FatJet_sv_normchi2', 'FatJet_sv_ntracks', 'FatJet_sv_phirel', \\\n",
    "#              'FatJet_sv_pt', 'FatJet_sv_ptrel', \\\n",
    "#             ]\n",
    "\n",
    "features = sorted(features)\n",
    "\n",
    "root_dir = \"/eos/user/a/afriberg/datasets/QCD_samples/\"\n",
    "\n",
    "dirs = os.listdir(root_dir)\n",
    "\n",
    "first_file = dirs.pop(0)\n",
    "while \".root\" not in first_file:\n",
    "    first_file = dirs.pop(0)\n",
    "\n",
    "first_file = root_dir + first_file\n",
    "df = get_df(first_file, '*')\n",
    "# Select a particular type of particle 0 means QCD\n",
    "df.query(\"FatJet_gen_hadronFlavour == 0\", inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df = df[features]\n",
    "# Prior to this, df is a pandas dataframe\n",
    "X = df.to_numpy().astype(np.float32)\n",
    "print(np.shape(X))\n",
    "\n",
    "\n",
    "for inputfile in dirs:\n",
    "    if \".root\" not in inputfile:\n",
    "        continue\n",
    "    inputfile = root_dir + inputfile\n",
    "    df = get_df(inputfile, '*')\n",
    "    df.dropna(inplace=True)\n",
    "    df = df[features]\n",
    "    # Prior to this, df is a pandas dataframe\n",
    "    next_data = df.to_numpy().astype(np.float32)\n",
    "    print(f\"next data has shape {np.shape(next_data)}\")\n",
    "    # appending it to the whole thing\n",
    "    X = np.append(X, next_data, axis=0)\n",
    "\n",
    "print(f\"X has shape {np.shape(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-occupation",
   "metadata": {},
   "source": [
    "# Run this when you want to add HToBB Data to the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tropical-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = \"/eos/user/a/afriberg/datasets/has_B/ZH_HToBB_ZToLL_M125_13TeV_powheg_pythia8.root\"\n",
    "df = get_df(new_path, '*')\n",
    "# Select a particular type of particle 4 means Charm 5 means B quark?\n",
    "df.query(\"FatJet_gen_hadronFlavour == 5\", inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df = df[features]\n",
    "\n",
    "new_X = df.to_numpy()\n",
    "new_X = new_X.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-trigger",
   "metadata": {},
   "source": [
    "This scales the HToBB data and the QCD data together, and then splits them in two parts afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "several-middle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X now has shape (1906786, 59)\n",
      " new_X now has shape (23350, 59)\n"
     ]
    }
   ],
   "source": [
    "# num_new = np.size(new_X, axis=0)\n",
    "# X = np.append(X, new_X, axis=0)\n",
    "# print(f\"new_X has shape {np.shape(new_X)}\\nX has shape {np.shape(X)}\")\n",
    "# print(np.allclose(X[-num_new:, :], new_X))\n",
    "\n",
    "# Scale our data using a MinMaxScaler that will scale\n",
    "# each number so that it will be between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "qcd_data = scaler.fit_transform(X)\n",
    "bb_data = scaler.transform(new_X)\n",
    "\n",
    "print(f\"X now has shape {np.shape(X)}\\n new_X now has shape {np.shape(new_X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "distant-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_qcd = []\n",
    "# X_bb = []\n",
    "# scaler.fit_transform(X_qcd)\n",
    "# scaler.transform(x)\n",
    "# print(bb_data[np.argmax(bb_data, axis=0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-humor",
   "metadata": {},
   "source": [
    "## Run this regardless of presence or lack of HToBB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "psychological-peter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test = train_test_split(qcd_data, test_size=0.20)\n",
    "original_dim = np.size(qcd_data, axis=1)\n",
    "print(original_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "listed-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "def build_dset(df): \n",
    "    df = df.copy()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((df, df))\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "    \n",
    "x_train_dataset = build_dset(x_train)\n",
    "x_test_dataset = build_dset(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-ridge",
   "metadata": {},
   "source": [
    "### loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "spoken-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the encoding vector.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-fighter",
   "metadata": {},
   "source": [
    "### build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deluxe-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder(original_dim, latent_dim):\n",
    "    # Encoder\n",
    "    encoder_inputs = layers.Input(shape=(original_dim,))\n",
    "    h = layers.Dense(32, activation='relu')(encoder_inputs)\n",
    "    h = layers.Dense(16, activation='relu')(h)\n",
    "    h = layers.Dense(8, activation='relu')(h)\n",
    "    h = layers.Dense(latent_dim, activation='sigmoid')(h)\n",
    "    z_mu = layers.Dense(latent_dim, name=\"z_mean\")(h)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(h)\n",
    "    z = Sampling()([z_mu, z_log_var])\n",
    "    \n",
    "    encoder = Model(encoder_inputs, [z_mu, z_log_var, z], name=\"encoder\")\n",
    "    return encoder\n",
    "    \n",
    "def get_decoder(original_dim, latent_dim):\n",
    "    decoder_inputs = layers.Input(shape=(latent_dim,))\n",
    "    d = layers.Dense(8, activation='relu')(decoder_inputs)\n",
    "    d = layers.Dense(16, activation='relu')(d)\n",
    "    d = layers.Dense(32, activation='relu')(d)\n",
    "    d = layers.Dense(original_dim, activation='softmax')(d)\n",
    "    \n",
    "    decoder = Model(decoder_inputs, d, name=\"decoder\")\n",
    "    return decoder\n",
    "\n",
    "class vae(Model):\n",
    "    def __init__(self, encoder, decoder, verbose=True, **kwargs):\n",
    "        super(vae, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "        \n",
    "        if verbose:\n",
    "            self.encoder.summary()\n",
    "            self.decoder.summary()\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    tf.keras.losses.binary_crossentropy(data, reconstruction), axis=-1\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.encoder.trainable_weights + self.decoder.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.encoder.trainable_weights + self.decoder.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def call(self, data):\n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        y_pred = self.decoder(z)\n",
    "        return y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-bunch",
   "metadata": {},
   "source": [
    "### get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "complete-roads",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 59)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           1920        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           528         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            136         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            18          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            6           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            6           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sampling (Sampling)             (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,614\n",
      "Trainable params: 2,614\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 59)                1947      \n",
      "=================================================================\n",
      "Total params: 2,659\n",
      "Trainable params: 2,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "with strategy.scope():\n",
    "    encoder = get_encoder(original_dim, latent_dim)\n",
    "    decoder = get_decoder(original_dim, latent_dim)\n",
    "    model = vae(encoder, decoder)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1.e-3))\n",
    "    #model.compile(optimizer=tf.keras.optimizers.RMSprop())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-going",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_callback():\n",
    "    lr_start   = 0.000001\n",
    "    lr_max     = 0.01\n",
    "    lr_min     = 0.000001\n",
    "    lr_ramp_ep = 5\n",
    "    lr_sus_ep  = 10\n",
    "    lr_decay   = 0.8\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        return lr\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n",
    "    return lr_callback\n",
    "\n",
    "checkpoint_path = \"checkpoints/no_sv_vars.{epoch:05d}.hdf5\"\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 monitor = 'val_loss',\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=False,\n",
    "                                                 mode = 'min',\n",
    "                                                 verbose=1)\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "history = model.fit(\n",
    "    x_train_dataset,\n",
    "    shuffle=True,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[cp_callback]\n",
    "    #callbacks=[cp_callback, get_lr_callback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test)\n",
    "predictions = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history[\"loss\"][12:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-surname",
   "metadata": {},
   "source": [
    "# Loading a model from a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "large-copper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 59)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           1920        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           528         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 8)            136         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2)            18          dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            6           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            6           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sampling_1 (Sampling)           (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,614\n",
      "Trainable params: 2,614\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 59)                1947      \n",
      "=================================================================\n",
      "Total params: 2,659\n",
      "Trainable params: 2,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "11918/11918 [==============================] - 8s 686us/step - total_loss: 0.0000e+00 - reconstruction_loss: 0.0000e+00 - kl_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "encoder = get_encoder(original_dim, latent_dim)\n",
    "decoder = get_decoder(original_dim, latent_dim)\n",
    "model = vae(encoder, decoder)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1.e-3))\n",
    "model.evaluate(x_test)\n",
    "model.load_weights(\"no_sv_vars_checkpoints/no_sv_vars.00030.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-industry",
   "metadata": {},
   "source": [
    "# Plotting the test data errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(x_test)\n",
    "err = np.mean(np.abs(predict - x_test), axis=1)\n",
    "print(np.shape(err))\n",
    "\n",
    "bins = np.linspace(0, 0.4, 1000)\n",
    "# plt.hist(err, density=True)\n",
    "plt.hist(err, density=True, bins=bins)\n",
    "plt.xlabel(\"Mean Absolute Error\")\n",
    "plt.ylabel(\"Number of events (density)\")\n",
    "# Getting the name of the file we ran on\n",
    "plt.title(\"Aggregate QCD Data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-twins",
   "metadata": {},
   "source": [
    "## Trying to predict BB quarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-category",
   "metadata": {},
   "source": [
    "Adding all of the data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "qcd_label = np.zeros(shape=(np.size(new_X, axis=0), 1))\n",
    "bb_label = np.ones(shape=(np.size(x_test, axis=0), 1))\n",
    "\n",
    "print(np.shape(new_X))\n",
    "qcd_true = np.hstack((new_X, qcd_label))\n",
    "print(np.shape(qcd_true))\n",
    "\n",
    "print(np.shape(x_test))\n",
    "bb_true = np.hstack((x_test, bb_label))\n",
    "print(np.shape(bb_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-green",
   "metadata": {},
   "source": [
    "Putting all of the data in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the data together and randomize it\n",
    "total_matrix = np.append(bb_true, qcd_true, axis=0)\n",
    "np.random.shuffle(total_matrix)\n",
    "print(np.shape(total_matrix))\n",
    "# Making test data with the correct labels (whether its a b quark or not)\n",
    "test_matrix = total_matrix[:, :original_dim]\n",
    "test_labels = total_matrix[:, original_dim]\n",
    "print(np.shape(test_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-underground",
   "metadata": {},
   "source": [
    "Getting the error for every prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(test_matrix)\n",
    "diff = test_matrix - predict\n",
    "mae_err = np.mean(np.abs(diff), axis = 1)\n",
    "sq_err = np.mean(np.square(diff), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mae_err[np.argmax(mae_err)])\n",
    "print(mae_err[np.argmin(mae_err)])\n",
    "\n",
    "bins = 20\n",
    "bins = np.linspace(0, 25, 100)\n",
    "plt.hist(mae_err, bins=bins, alpha=0.5, label=\"MAE Error\", density=True)\n",
    "plt.hist(sq_err, bins=bins, alpha=0.5, label=\"Mean Square Error\", density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-dover",
   "metadata": {},
   "source": [
    "### Plotting the latent space distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.encoder\n",
    "z_mean, z_log_var, z = encoder.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(z[0], z[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-importance",
   "metadata": {},
   "source": [
    "### Plotting ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_fpr, mae_tpr, mae_threshold = roc_curve(test_labels, mae_err)\n",
    "sq_fpr, sq_tpr, sq_threshold = roc_curve(test_labels, sq_err)\n",
    "\n",
    "mae_auc = auc(mae_fpr, mae_tpr)\n",
    "sq_auc = auc(sq_fpr, sq_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(mae_fpr, mae_tpr, label=\"MAE\")\n",
    "# plt.plot(sq_fpr, sq_tpr, label=\"Mean Square Error\")\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "desirable-practice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey. We made it\n"
     ]
    }
   ],
   "source": [
    "print(\"Hey. We made it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-fourth",
   "metadata": {},
   "source": [
    "### Plotting BB error vs QCD error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "visible-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_predict = model.predict(new_X)\n",
    "qcd_predict = model.predict(X)\n",
    "bb_err = np.mean(np.abs(bb_predict, new_X), axis=1)\n",
    "qcd_err = np.mean(np.abs(qcd_predict, X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "latest-kingston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEICAYAAABbOlNNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAASdklEQVR4nO3dfaxk9V3H8fenbIuNLRXKgusudbFFIzSR2hVJtIrBlG21BbU1i42sEbO2ocb6EAOtDzVxk6KpGLRgMCBLQwtYbcAHtIRqG00FLxV5aresgN3truxWsGJjqUu//jG/287v7tzHuffOXff9Sk7mzPf8fme+czjZz51z5l5SVUiSNO15k25AkrS2GAySpI7BIEnqGAySpI7BIEnqGAySpI7BoGNSkieS/OAs285Lsm+1e5LWCoNBktQxGKRVlGTdiNpxi9zHosZLi2Uw6Fj2XUkeSfJ0kj9O8nXDG5O8M8nn22Wnt8y2kyQvSXJ9kgNJPpfkt6b/8U7yU0n+IclVSZ4C3p3kxiTXJvmrJF8EfiDJtyf5uyT/meThJG8c2v8R41foeEiAwaBj21uAC4CXA98K/OrQtm8ETgY2AtuB65J82yz72QUcBl4BvAp4LfAzQ9u/G3gMOAXY2Wo/0dZfDNwD/DnwkTbm54CbZ7ze8Pi/X/xblRbOYNCx7A+qam9VPcXgH92LZ2z/tap6tqo+Bvwl8OMzd5DkVOB1wDuq6otVdRC4Ctg2NGx/Vf1+VR2uqv9ptdur6h+q6ivA2cCLgPdU1Zer6qPAX8zo56vjq+pL4791aXZHXO+UjiF7h9b/DfimoedPV9UX59g+7ZuB5wMHkkzXnjdj33tnTppR+yZgbwuJ4dfbOM8+pBVhMOhYdtrQ+suA/UPPT0zy9UPh8DLgoRH72As8C5xcVYdneZ1Rf8J4uLYfOC3J84bC4WXAZ+bZh7QivJSkY9llSTYlOQl4J3DrjO2/meQFSV4D/DDwJzN3UFUHGNwbeG+SE5I8L8nLk3z/Ivq4B/gi8CtJnp/kPOANwC2Lf0vS+AwGHcs+wOAf9cfa8ltD2/4deJrBT/M3A2+tqk/Psp9LgBcAj7Q5HwI2LLSJqvoy8EYG9yo+D1wDXDLH60krKv6PeiRJw/zEIEnqGAySpI7BIEnqGAySpM5R+3sMJ598cm3evHnSbUjSUeW+++77fFWtn2vMURsMmzdvZmpqatJtSNJRJcm/zTfGS0mSpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpM5R+5vPkrRYmy//y+75E+/5oQl1srb5iUGS1DEYJEkdg0GS1DEYJEkdg0GS1DEYJEkdg0GS1DEYJEkdg0GS1DEYJEkdg0GS1DEYJEkdg0GS1DEYJEkdg0GS1DEYJEkdg0GS1DEYJEkdg0GS1DEYJEkdg0GS1DEYJEkdg0GS1DEYJEkdg0GS1Jk3GJKcluRvk3wqycNJfr7VT0pyV5JH2+OJQ3OuSLInye4kFwzVX53kwbbt6iRp9eOT3Nrq9yTZvALvVZK0AAv5xHAY+KWq+nbgXOCyJGcClwN3V9UZwN3tOW3bNuAsYCtwTZLj2r6uBXYAZ7Rla6tfCjxdVa8ArgKuXIb3JklagnmDoaoOVNUn2/ozwKeAjcCFwK42bBdwUVu/ELilqp6tqseBPcA5STYAJ1TVJ6qqgJtmzJne14eA86c/TUiSVtei7jG0SzyvAu4BTq2qAzAID+CUNmwjsHdo2r5W29jWZ9a7OVV1GPgC8NIRr78jyVSSqUOHDi2mdUnSAi04GJK8CPhT4B1V9V9zDR1Rqznqc83pC1XXVdWWqtqyfv36+VqWJC3BgoIhyfMZhMLNVfVnrfxkuzxEezzY6vuA04ambwL2t/qmEfVuTpJ1wEuApxb7ZiRJ41vIt5ICXA98qqp+d2jTHcD2tr4duH2ovq190+h0BjeZ722Xm55Jcm7b5yUz5kzv603AR9t9CEnSKlu3gDHfA/wk8GCS+1vtncB7gNuSXAp8FngzQFU9nOQ24BEG32i6rKqea/PeBtwIvBC4sy0wCJ73J9nD4JPCtvHeliRpqeYNhqr6e0bfAwA4f5Y5O4GdI+pTwCtH1L9ECxZJ0mT5m8+SpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqzBsMSW5IcjDJQ0O1dyf5XJL72/L6oW1XJNmTZHeSC4bqr07yYNt2dZK0+vFJbm31e5JsXub3KElahIV8YrgR2DqiflVVnd2WvwJIciawDTirzbkmyXFt/LXADuCMtkzv81Lg6ap6BXAVcOUS34skaRnMGwxV9XHgqQXu70Lglqp6tqoeB/YA5yTZAJxQVZ+oqgJuAi4amrOrrX8IOH/604QkafWNc4/h7UkeaJeaTmy1jcDeoTH7Wm1jW59Z7+ZU1WHgC8BLR71gkh1JppJMHTp0aIzWJUmzWWowXAu8HDgbOAC8t9VH/aRfc9TnmnNkseq6qtpSVVvWr1+/qIYlSQuzpGCoqier6rmq+grwR8A5bdM+4LShoZuA/a2+aUS9m5NkHfASFn7pSpK0zJYUDO2ewbQfAaa/sXQHsK190+h0BjeZ762qA8AzSc5t9w8uAW4fmrO9rb8J+Gi7DyFJmoB18w1I8kHgPODkJPuA3wDOS3I2g0s+TwA/C1BVDye5DXgEOAxcVlXPtV29jcE3nF4I3NkWgOuB9yfZw+CTwrZleF+SpCWaNxiq6uIR5evnGL8T2DmiPgW8ckT9S8Cb5+tDkrQ6/M1nSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVJn3mBIckOSg0keGqqdlOSuJI+2xxOHtl2RZE+S3UkuGKq/OsmDbdvVSdLqxye5tdXvSbJ5md+jJGkRFvKJ4UZg64za5cDdVXUGcHd7TpIzgW3AWW3ONUmOa3OuBXYAZ7Rlep+XAk9X1SuAq4Arl/pmJEnjmzcYqurjwFMzyhcCu9r6LuCiofotVfVsVT0O7AHOSbIBOKGqPlFVBdw0Y870vj4EnD/9aUKStPqWeo/h1Ko6ANAeT2n1jcDeoXH7Wm1jW59Z7+ZU1WHgC8BLR71okh1JppJMHTp0aImtS5Lmstw3n0f9pF9z1Oeac2Sx6rqq2lJVW9avX7/EFiVJc1lqMDzZLg/RHg+2+j7gtKFxm4D9rb5pRL2bk2Qd8BKOvHQlSVolSw2GO4DtbX07cPtQfVv7ptHpDG4y39suNz2T5Nx2/+CSGXOm9/Um4KPtPoQkaQLWzTcgyQeB84CTk+wDfgN4D3BbkkuBzwJvBqiqh5PcBjwCHAYuq6rn2q7exuAbTi8E7mwLwPXA+5PsYfBJYduyvDNJ0pLMGwxVdfEsm86fZfxOYOeI+hTwyhH1L9GCRZI0ef7msySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpM1YwJHkiyYNJ7k8y1WonJbkryaPt8cSh8Vck2ZNkd5ILhuqvbvvZk+TqJBmnL0nS0i3HJ4YfqKqzq2pLe345cHdVnQHc3Z6T5ExgG3AWsBW4Jslxbc61wA7gjLZsXYa+JElLsBKXki4EdrX1XcBFQ/VbqurZqnoc2AOck2QDcEJVfaKqCrhpaI4kaZWNGwwFfCTJfUl2tNqpVXUAoD2e0uobgb1Dc/e12sa2PrN+hCQ7kkwlmTp06NCYrUuSRlk35vzvqar9SU4B7kry6TnGjrpvUHPUjyxWXQdcB7Bly5aRYyRJ4xnrE0NV7W+PB4EPA+cAT7bLQ7THg234PuC0oembgP2tvmlEXZI0AUsOhiRfn+TF0+vAa4GHgDuA7W3YduD2tn4HsC3J8UlOZ3CT+d52uemZJOe2byNdMjRHkrTKxrmUdCrw4fbN0nXAB6rqr5P8E3BbkkuBzwJvBqiqh5PcBjwCHAYuq6rn2r7eBtwIvBC4sy2SpAlYcjBU1WPAd4yo/wdw/ixzdgI7R9SngFcutRdJ0vLxN58lSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUMRgkSR2DQZLUWTPBkGRrkt1J9iS5fNL9SNKxak0EQ5LjgPcBrwPOBC5OcuZku5KkY9OaCAbgHGBPVT1WVV8GbgEunHBPknRMWjfpBpqNwN6h5/uA7545KMkOYEd7+t9Jdi/x9U4GPr/EuSvJvhbHvhZvrfY2kb5y5bxD/j8er2+eb8BaCYaMqNURharrgOvGfrFkqqq2jLuf5WZfi2Nfi7dWe7OvxVnpvtbKpaR9wGlDzzcB+yfUiyQd09ZKMPwTcEaS05O8ANgG3DHhniTpmLQmLiVV1eEkbwf+BjgOuKGqHl7Blxz7ctQKsa/Fsa/FW6u92dfirGhfqTriUr4k6Ri2Vi4lSZLWCINBktSrqqNuAbYCu4E9wOUjtge4um1/APjO+eYCJwF3AY+2xxOHtl3Rxu8GLljlvn4H+HQb/2HgG1p9M/A/wP1t+cNV7uvdwOeGXv/1a+R43TrU0xPA/Ys9XsvQ2w3AQeChGXMmfY7N1tekz7HZ+pr0OTZbX2OfY0vti8G3N/8W+BTwMPDzy3l+fXX8fAPW2sLg5vS/At8CvAD4F+DMGWNeD9zZDu65wD3zzQV+e/o/EHA5cGVbP7ONOx44vc0/bhX7ei2wrq1fOdTX5pkn7Cofr3cDvzzi9SZ6vGbMfy/w64s5XuP21rZ9H/CdM19vkufYPH1N7Bybp6+JnWNz9TXuOTZOX8AGvhYSLwY+wzL9Gza8HI2Xkhby5zMuBG6qgX8EviHJhnnmXgjsauu7gIuG6rdU1bNV9TiD1D1ntfqqqo9U1eE2/x8Z/I7HYqzU8ZrNRI/XtCQBfhz44Dz9jjJOb1TVx4GnRux3kufYrH1N+Byb63jNZqLHa9oY59iS+6qqA1X1ydbfMww+OWwcmjPO+fVVR2MwjPrzGRsXOGauuadW1QGA9njKIl5vJfsa9tMMfoqYdnqSf07ysSSvGTF+pft6e5IHktyQ5MRFvN5K9wXwGuDJqnp0qLaQ4zVub3OZ5Dm2UKt9js1nUufYQiz1HFuWvpJsBl4F3NNK455fX3U0BsNC/nzGbGMW9Kc3lvB6K95XkncBh4GbW+kA8LKqehXwi8AHkpywin1dC7wcOLv18t5FvN5K9jXtYvqf5BZ6vMbtbSlW45jN38RkzrG5TPIcW4ilnmNj95XkRcCfAu+oqv+ap89Fv8ejMRgW8uczZhsz19wnpz9CtseDi3i9leyLJNuBHwbeUu2iYftY+B9t/T4G1w2/dbX6qqonq+q5qvoK8Ed87aPpWjhe64AfZXCTkNbvQo/XuL3NZZLn2JwmeI7NasLn2JzGPMfG6ivJ8xmEws1V9WdDY8Y9v76mFnAzbi0tDH5b+zEGN1Gmb9ycNWPMD9HfuLl3vrkMvpkxfOPmt9v6WfQ3bh5j9I2uleprK/AIsH7GvtZP98HgJtbngJNWsa8NQ/N/gcE1zIkfr6Fj9rGlHK9xexvavpnR3/6ZyDk2T18TO8fm6Wti59hcfY17jo3TV3t+E/B7I/Y71vnV7WuujWt1YXDH/jMMEvldrfZW4K1DB+99bfuDwJa55rb6S4G7GXzV6+7h/6DAu9r43cDrVrmvPQyuD97P0FfggB9j8HW1fwE+Cbxhlft6fxv7AIO/a7VhLRyvtu3G6X0M1RZ8vJahtw8yuKzwvwx+Wrt0jZxjs/U16XNstr4mfY6N7Gs5zrGl9gV8L4PLQA8w42u8LMP5Nb34JzEkSZ2j8R6DJGkFGQySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnq/B9vCy+/+XKhvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins=200\n",
    "bins = np.linspace(0, 0.02, 100)\n",
    "plt.hist(bb_err, bins=bins)\n",
    "plt.title(\"bb error\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(qcd_err, bins=bins)\n",
    "plt.title(\"qcd error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "legitimate-comparison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins=np.linspace(0.0125, 0.02, 100)\n",
    "alpha=0.5\n",
    "\n",
    "plt.hist(bb_err, density=True, bins=bins, label=\"BB Error\", alpha=alpha)\n",
    "plt.hist(qcd_err, density=True, bins=bins, label=\"QCD Error\", alpha=alpha)\n",
    "plt.title(\"Both errors\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-parent",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
